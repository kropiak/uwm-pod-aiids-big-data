{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4178d9f-a2a4-450d-93a1-42e5fe273e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T09:00:30.838523Z",
     "iopub.status.busy": "2024-11-06T09:00:30.837851Z",
     "iopub.status.idle": "2024-11-06T09:00:30.843573Z",
     "shell.execute_reply": "2024-11-06T09:00:30.842599Z",
     "shell.execute_reply.started": "2024-11-06T09:00:30.838498Z"
    }
   },
   "source": [
    "# Lab 6 - PySpark DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea13e6-18cc-425f-aa97-7a9380008eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T09:01:33.284355Z",
     "iopub.status.busy": "2024-11-06T09:01:33.283808Z",
     "iopub.status.idle": "2024-11-06T09:01:33.288379Z",
     "shell.execute_reply": "2024-11-06T09:01:33.287266Z",
     "shell.execute_reply.started": "2024-11-06T09:01:33.284327Z"
    }
   },
   "source": [
    "# 0. Uruchomienie silnika Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c0e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dla instalacji lokalnej\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_HOME'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8637d578-2dda-4f7d-b152-e14aa8afe51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\hadoop', 'C:\\\\Program Files\\\\OpenLogic\\\\jdk-17.0.15.6-hotspot')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['HADOOP_HOME'], os.environ['JAVA_HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3113597e-c473-4281-b4d6-3df999b97a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c:\\\\Users\\\\Krzysztof\\\\__projects\\\\__pyspark_local_aiids\\\\.venv\\\\Scripts\\\\python.exe',\n",
       " 'c:\\\\Users\\\\Krzysztof\\\\__projects\\\\__pyspark_local_aiids\\\\.venv\\\\Scripts\\\\python.exe',\n",
       " 'c:\\\\Users\\\\Krzysztof\\\\__projects\\\\__pyspark_local_aiids\\\\.venv\\\\Scripts\\\\python.exe')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PYSPARK_HOME'], os.environ['PYSPARK_DRIVER_PYTHON'], os.environ['PYSPARK_PYTHON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "767163ce-858c-4b31-9908-6c6c5fd8107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.9\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b77cf-2391-4f51-b98a-9002bc22d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dla instalacji z dockerem\n",
    "\n",
    "import os\n",
    "os.environ['SPARK_NAME'] = \"/opt/spark\"\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "# os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/opt/spark/work-dir/.venv/bin/python3'\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/spark/work-dir/.venv/bin/python3'\n",
    "\n",
    "# można też spróbować wykorzystać moduł findspark do automatycznego odnalezienia miejsca instalacji sparka\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "# lub\n",
    "# findspark.init(\"/opt/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7a59b7-ad6d-43ff-b5dd-2bc48d45bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.master(\"spark://spark-master:7077\").appName(\"Create-DataFrame\").getOrCreate()\n",
    "# konfiguracja z określeniem liczby wątków (2) oraz ilości pamięci do wykorzystania poza stertą interpretera Pythona\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"local[2]\")\\\n",
    "        .appName(\"Create-DataFrame\")\\\n",
    "        .config(\"spark.executor.memory\", \"4g\") \\\n",
    "        .config(\"spark.driver.memory\", \"2g\") \\\n",
    "        .config(\"spark.memory.offHeap.enabled\",\"true\")\\\n",
    "        .config(\"spark.memory.offHeap.size\",\"4g\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3710fc1a-6e5d-4195-a9b4-63970603cb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-L9AQONII:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Create-DataFrame</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=Create-DataFrame>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7395a6ae-0a2d-441d-aa31-9c865a858554",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f6ad4-573a-4f01-a7e7-123aae9d67e7",
   "metadata": {},
   "source": [
    "# 1. Spark DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe4562-1c8d-4492-be4d-dc974c5cf97a",
   "metadata": {},
   "source": [
    "> Spark Dataframe API: https://spark.apache.org/docs/3.5.3/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html\n",
    "\n",
    "Zanim przejdziemy do obiektów typu DataFrame warto powiedzieć, że w systemie Spark występuje również tym Dataset, co może prowadzić do używania tych dwóch terminów zamiennie, co byłoby błędem. Obiekty typu Dataset są odrębnym typem i póki co nie są one dostępne w API Pythona dla Sparka, ale można na nich pracować z poziomu API Javy oraz języka Scala.\n",
    "Kilka szczegółów na temat tego typu oraz jego tworzenia z poziomu języka Java lub Scala można znaleźć [tu](https://spark.apache.org/docs/3.5.3/sql-getting-started.html#creating-datasets) oraz [tu](https://spark.apache.org/docs/3.5.3/api/java/index.html).\n",
    "Obiekty typu Dataset w języku Java i Scala są obiektami silnie typowanymi, więc mamy do dyspozycji transfomacje typowane, a w Pythonie są to transformacje nietypowane (z racji natury języka Python).\n",
    "\n",
    "Spark DataFrame to rozproszona kolekcja danych Spark do pracy z danymi ustrukturyzowanymi, która podobna jest do obiektów DataFrame znanych z biblioteki pandas oraz języka R jednak dużo bardziej zoptymalizowana w kontekście pracy w środowisku rozproszonym. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a70aaf-6452-4c77-9589-f5ac6def809a",
   "metadata": {},
   "source": [
    "## Pobranie danych i wczytanie do ramki Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bee8f774-9eea-4111-bff1-482f58644e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 61365    0 61365    0     0  44491      0 --:--:--  0:00:01 --:--:-- 44629\n",
      "100  835k    0  835k    0     0   349k      0 --:--:--  0:00:02 --:--:--  349k\n",
      "100 1907k    0 1907k    0     0   565k      0 --:--:--  0:00:03 --:--:--  565k\n",
      "100 2064k    0 2064k    0     0   609k      0 --:--:--  0:00:03 --:--:--  610k\n"
     ]
    }
   ],
   "source": [
    "# pobranie spakowanego zbioru za pomocą polecenia systemowego wget\n",
    "# strona datasetu: https://archive.ics.uci.edu/dataset/911/recipe+reviews+and+user+feedback+dataset\n",
    "# to zadziała tylko w systemach Linux, w Windows można użyć polecenia curl\n",
    "# !wget https://archive.ics.uci.edu/static/public/911/recipe+reviews+and+user+feedback+dataset.zip\n",
    "\n",
    "# Windows\n",
    "!curl -O https://archive.ics.uci.edu/static/public/911/recipe+reviews+and+user+feedback+dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20ebf782-215c-49da-81eb-1265ea547e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_pyspark_introduction.ipynb\n",
      "01_pyspark_introduction_with_solutions.ipynb\n",
      "02_pyspark_dataframes.ipynb\n",
      "clean_words.json\n",
      "data\n",
      "recipe+reviews+and+user+feedback+dataset.zip\n"
     ]
    }
   ],
   "source": [
    "# listujemy zawartość bieżącego folderu (również Linux, ale jak mamy WSL to i Windows)\n",
    "!ls\n",
    "\n",
    "# Windows\n",
    "# !dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d49baef0-8049-4c01-b263-b35c4e95883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmiana nazwy pliku - nie jest konieczna, ale trzeba zmienić później ścieżkę w kolejnej komórce notatnika\n",
    "# !mv recipe+reviews+and+user+feedback+dataset.zip recipe_reviews.zip\n",
    "\n",
    "# Windows\n",
    "!ren recipe+reviews+and+user+feedback+dataset.zip recipe_reviews.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "812e3726-b836-43ba-b68d-3e07f126349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wypakowujemy plik do podfolderu data\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"recipe_reviews.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "894baa64-c727-49e0-a4e6-51f4cb602281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pan-tadeusz.txt\n",
      "polish.stopwords.txt\n",
      "Recipe Reviews and User Feedback Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ./data\n",
    "\n",
    "# lub\n",
    "# !dir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2fe79ad-a36f-4cdd-b3e7-3d09d0aa8d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",recipe_number,recipe_code,recipe_name,comment_id,user_id,user_name,user_reputation,created_at,reply_count,thumbs_up,thumbs_down,stars,best_score,text\n",
      "0,001,14299,Creamy White Chili,sp_aUSaElGf_14299_c_2G3aneMRgRMZwXqIHmSdXSG1hEM,u_9iFLIhMa8QaG,Jeri326,1,1665619889,0,0,0,5,527,\"I tweaked it a little, removed onions because of onion haters in my house, used Italian seasoning instead of just oregano, and use a paprika/ cayenne mix and a little more than the recipe called for.. we like everything a bit more hot. The chili was amazing! It was easy to make and everyone absolutely loved it. It will now be a staple meal in our house.\"\n",
      "1,001,14299,Creamy White Chili,sp_aUSaElGf_14299_c_2FsPC83HtzCsQAtOxlbL6RcaPbY,u_Lu6p25tmE77j,Mark467,50,1665277687,0,7,0,5,724,\"Bush used to have a white chili bean and it made this recipe super simple. Iâ€™ve written to them and asked them to please!, bring them back\"\n"
     ]
    }
   ],
   "source": [
    "# sprawdzamy jak wyglądają 3 pierwsze linie pliku, widać, że pierwsza zawiera nagłówki kolumn a dane są oddzielone przecinkiem\n",
    "# Linux, mac i WSL\n",
    "!head -3 \"data/Recipe Reviews and User Feedback Dataset.csv\"\n",
    "# 3 ostatnie linie z pliku\n",
    "# !tail -3 \"data/Recipe Reviews and User Feedback Dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "972c4ffe-008e-49ce-98e7-7895b6dcfc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = spark.read.csv('./data/Recipe Reviews and User Feedback Dataset.csv', header=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7293cf-7cde-457c-8447-fd3baecffe15",
   "metadata": {},
   "source": [
    "## Wyświetlenie danych oraz schematu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "951bf79d-c58e-4f53-8364-b365d4ab729e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------+------------------+--------------------+--------------+----------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "|_c0|recipe_number|recipe_code|       recipe_name|          comment_id|       user_id| user_name|user_reputation|created_at|reply_count|thumbs_up|thumbs_down|stars|best_score|                text|\n",
      "+---+-------------+-----------+------------------+--------------------+--------------+----------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "|  0|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_9iFLIhMa8QaG|   Jeri326|              1|1665619889|          0|        0|          0|    5|       527|I tweaked it a li...|\n",
      "|  1|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_Lu6p25tmE77j|   Mark467|             50|1665277687|          0|        7|          0|    5|       724|Bush used to have...|\n",
      "|  2|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_s0LwgpZ8Jsqq|Barbara566|             10|1664404557|          0|        3|          0|    5|       710|I have a very com...|\n",
      "|  3|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_fqrybAdYjgjG|jeansch123|              1|1661787808|          2|        2|          0|    0|       581|In your introduct...|\n",
      "|  4|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_XXWKwVhKZD69|  camper77|             10|1664913823|          1|        7|          0|    0|       820|Wonderful! I made...|\n",
      "+---+-------------+-----------+------------------+--------------------+--------------+----------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# najpopularniejsza metoda ich pobrania to show(), ale jest ich więcej\n",
    "df_reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "537f476f-789c-49ae-b0fc-9ba8dbde22bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- recipe_number: string (nullable = true)\n",
      " |-- recipe_code: string (nullable = true)\n",
      " |-- recipe_name: string (nullable = true)\n",
      " |-- comment_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_reputation: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- reply_count: string (nullable = true)\n",
      " |-- thumbs_up: string (nullable = true)\n",
      " |-- thumbs_down: string (nullable = true)\n",
      " |-- stars: string (nullable = true)\n",
      " |-- best_score: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rzut oka na schemę tego DataFrame\n",
    "df_reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd6f927-53e5-4d69-b852-69156e29d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widać, że wszystkie kolumny są typu string, to jest domyślny sposób wczytywania danych przez spark z plain text\n",
    "# możemy jednak przekazać dodatkowy parametr, który na podstawie próbki danych spróbuje dobrać typ danych odpowiedni dla kolumny\n",
    "df_reviews = spark.read.csv('./data/Recipe Reviews and User Feedback Dataset.csv', header=True, sep=\",\", inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae798ec2-2892-4667-8cad-022013cd517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- recipe_number: string (nullable = true)\n",
      " |-- recipe_code: string (nullable = true)\n",
      " |-- recipe_name: string (nullable = true)\n",
      " |-- comment_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_reputation: string (nullable = true)\n",
      " |-- created_at: integer (nullable = true)\n",
      " |-- reply_count: integer (nullable = true)\n",
      " |-- thumbs_up: integer (nullable = true)\n",
      " |-- thumbs_down: integer (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- best_score: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# po wypisaniu schemy widać zmianę\n",
    "df_reviews.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472be25-b43e-4758-85f8-b6f46225d957",
   "metadata": {},
   "source": [
    "> Listę dostępnych typów danych znajdziesz tu: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/data_types.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c7dc0cb-9964-47cc-9529-8d03d9db5383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ramkę możemy również inicjalizować wskazując pożądane typy danych\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DecimalType, LongType\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",36636,\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",40288,\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",42114,\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",39192,\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",1000)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\", StringType(), True), \\\n",
    "    StructField(\"user_id\", StringType(), True), \\\n",
    "    StructField(\"lastname\", StringType(), True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    # błąd konwersji \"\" na int!\n",
    "    # StructField(\"id\", LongType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", StringType(), True)\n",
    "    # chcielibyśmy tak, ale tutaj nie da się za bardzo - błąd konwersji int na decimal!\n",
    "    # StructField(\"salary\", DecimalType(10,2), True) \\\n",
    "  ])\n",
    "\n",
    "df_test = spark.createDataFrame(data=data,schema=schema)\n",
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84bbe3b5-7962-4c3a-b1d7-1df7f302148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: decimal(10,2) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# możemy wykonać rzutowanie po wczytaniu danych z większością kolumn typu tekstowego\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_test = df_test.withColumn(\"salary\", F.col(\"salary\").cast(\"decimal(10,2)\"))\n",
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14479957-ba49-4365-baf7-501e1ec46f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| salary|\n",
      "+-------+\n",
      "|3000.00|\n",
      "|4000.00|\n",
      "|4000.00|\n",
      "|4000.00|\n",
      "|1000.00|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wyświetlenie danych z pojedynczej kolumny\n",
    "df_test.select(df_test.salary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98056a8a-8ad3-461e-ba71-7308a01cfd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18268"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ile wierszy w ramce?\n",
    "df_reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de6ae448-7944-473f-9a26-8d3eb0602712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Column<'user_name'>, Column<'user_name'>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame składa się z obiektów typu Column dla każdej kolumny\n",
    "# API dla typu Column: https://spark.apache.org/docs/3.5.3/api/python/reference/pyspark.sql/api/pyspark.sql.Column.html\n",
    "\n",
    "# do kolumn możemy się odwoływać tak jak w pandas API, ale wynik jest inny\n",
    "df_reviews.user_name, df_reviews['user_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a77416a1-5da4-44ce-9e75-087178da9940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| user_name|\n",
      "+----------+\n",
      "|   Jeri326|\n",
      "|   Mark467|\n",
      "|Barbara566|\n",
      "|jeansch123|\n",
      "|  camper77|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aby wyświetlić dane musimy wywoałać funkcję select na obiekcie dataframe\n",
    "\n",
    "df_reviews.select(df_reviews.user_name).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7cf3e7df-d636-4f63-9b53-2a2d11d8cad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[user_name: string, user_reputation: string]\n",
      "+----------+---------------+\n",
      "| user_name|user_reputation|\n",
      "+----------+---------------+\n",
      "|   Jeri326|              1|\n",
      "|   Mark467|             50|\n",
      "|Barbara566|             10|\n",
      "|jeansch123|              1|\n",
      "|  camper77|             10|\n",
      "+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do funkcji select możemy przekazać wiele kolumn a wywołania podobnie jak dla RDD są leniwe\n",
    "print(df_reviews.select(df_reviews.user_name, df_reviews.user_reputation))\n",
    "# musimy więc wywołać funkcję, której wykonanie \"zmusi\" Sparka do wyliczenia jej wartości lub jawnie wywołać np. show\n",
    "df_reviews.select(df_reviews.user_name, df_reviews.user_reputation).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d300f-a5cb-4055-8c0a-b526d57b1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# można zmienić to domyślne zachowanie Spark, ale zazwyczaj nie jest to dobry pomysł, chyba, że zbiór jest mały\n",
    "# zmieniamy to poprzez edycję poniższego parametru\n",
    "# spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ebd49bd-3d35-4057-bf31-4e204fffc0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "| user_name|user_reputation|\n",
      "+----------+---------------+\n",
      "|   Jeri326|              1|\n",
      "|   Mark467|             50|\n",
      "|Barbara566|             10|\n",
      "|jeansch123|              1|\n",
      "|  camper77|             10|\n",
      "+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lub indeksując kolumny innym sposobem\n",
    "df_reviews.select(df_reviews['user_name'],df_reviews['user_reputation']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d36ae0b8-025c-4ef6-af7c-c9dd79440fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------+-----------+----------+-------+---------+---------------+----------+-----------+---------+-----------+-----+----------+----+\n",
      "|_c0|recipe_number|recipe_code|recipe_name|comment_id|user_id|user_name|user_reputation|created_at|reply_count|thumbs_up|thumbs_down|stars|best_score|text|\n",
      "+---+-------------+-----------+-----------+----------+-------+---------+---------------+----------+-----------+---------+-----------+-----+----------+----+\n",
      "|  0|           45|         64|         74|        77|     80|       83|             84|        86|         86|       86|         86|   86|        86|  86|\n",
      "+---+-------------+-----------+-----------+----------+-------+---------+---------------+----------+-----------+---------+-----------+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "# policzymy teraz liczbę wartości NULL w każdej kolumnie\n",
    "df_reviews.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_reviews.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15258db5-e451-4fb3-a011-e5b60e10a222",
   "metadata": {},
   "source": [
    "## Filtrowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da562ec4-8bd2-409e-86f8-a217f3339403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+-----------+----------+-------+---------+---------------+----------+-----------+---------+-----------+-----+----------+----+\n",
      "|                  id|       recipe_number|recipe_code|recipe_name|comment_id|user_id|user_name|user_reputation|created_at|reply_count|thumbs_up|thumbs_down|stars|best_score|text|\n",
      "+--------------------+--------------------+-----------+-----------+----------+-------+---------+---------------+----------+-----------+---------+-----------+-----+----------+----+\n",
      "|      Thank you!!!!\"|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "| It was excellent!  |                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|The recipe was a ...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|A shoutout to the...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|This recipe is de...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "| like the time it...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|My one complaint ...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|Have never eaten ...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|I thinned the mix...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|When you write 1-...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|decided to make a...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|looked good.  I u...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|little sweeter th...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|I baked the crust...| just to crisp it...|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|I made it myself ...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|I will try adding...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|This recipe is a ...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "| big! I&#39;m wit...| WILL NOT MAKE it...|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|It says a small p...|                NULL|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "|                  So| I used the compl...|       NULL|       NULL|      NULL|   NULL|     NULL|           NULL|      NULL|       NULL|     NULL|       NULL| NULL|      NULL|NULL|\n",
      "+--------------------+--------------------+-----------+-----------+----------+-------+---------+---------------+----------+-----------+---------+-----------+-----+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rzućmy okiem na kilka wierszy gdzie w kolumnie recipe_name jest wartość NULL\n",
    "df_reviews.filter(df_reviews.recipe_code.isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "660092ce-6e2d-4c93-bd98-bae96edd9dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18182"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zapisanie do nowej ramki danych bez wartości pustych\n",
    "df_reviews_clean = df_reviews.na.drop()\n",
    "df_reviews_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1063f8da-8ae4-4796-ad3d-47f04b9a8e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------+-----------+----------+-------+---------+---------------+----------+-----------+---------+-----------+-----+----------+----+\n",
      "|_c0|recipe_number|recipe_code|recipe_name|comment_id|user_id|user_name|user_reputation|created_at|reply_count|thumbs_up|thumbs_down|stars|best_score|text|\n",
      "+---+-------------+-----------+-----------+----------+-------+---------+---------------+----------+-----------+---------+-----------+-----+----------+----+\n",
      "|  0|            0|          0|          0|         0|      0|        0|              0|         0|          0|        0|          0|    0|         0|   0|\n",
      "+---+-------------+-----------+-----------+----------+-------+---------+---------------+----------+-----------+---------+-----------+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dla pewności możemy to sprawdzić raz jeszcze\n",
    "df_reviews_clean.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_reviews_clean.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af647544-8fcf-40bc-9464-c2ec573a682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------+------------------+--------------------+--------------+----------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "|_c0|recipe_number|recipe_code|       recipe_name|          comment_id|       user_id|       user_name|user_reputation|created_at|reply_count|thumbs_up|thumbs_down|stars|best_score|                text|\n",
      "+---+-------------+-----------+------------------+--------------------+--------------+----------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "|  0|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_9iFLIhMa8QaG|         Jeri326|              1|1665619889|          0|        0|          0|    5|       527|I tweaked it a li...|\n",
      "|  1|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_Lu6p25tmE77j|         Mark467|             50|1665277687|          0|        7|          0|    5|       724|Bush used to have...|\n",
      "|  2|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_s0LwgpZ8Jsqq|      Barbara566|             10|1664404557|          0|        3|          0|    5|       710|I have a very com...|\n",
      "|  5|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_BALTQJIvWtYr|         nikhita|              1|1661354351|          0|        3|          1|    5|       518|amazing! my boyfr...|\n",
      "|  6|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_HuJVXMzQqJoI|       Sandy1256|              1|1644088805|          0|       11|          0|    5|       833|Wow!!!  This reci...|\n",
      "|  8|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_xDTU4BqIVIc9|           Quest|              1|1643933124|          0|        6|          0|    5|       693|I absolutely love...|\n",
      "|  9|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_cDoX9ujcQEoc|     Susannah953|              1|1643237839|          0|        0|          0|    5|       404|I make this a lot...|\n",
      "| 10|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_a1kMC63ejmcn|jillanglemyer810|              1|1643127683|          0|        3|          0|    5|       706|Best and easiest ...|\n",
      "| 11|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_rLDRFmNx35zU|       Leslie126|              1|1642892566|          0|        2|          1|    5|       617|Best white chili ...|\n",
      "| 12|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_lPW6uyGJNSN0|       Cindy4876|              1|1642353692|          0|        1|          0|    5|       633|This recipe was e...|\n",
      "+---+-------------+-----------+------------------+--------------------+--------------+----------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filtrowanie danych z ramki\n",
    "df_reviews_clean.filter(df_reviews.user_name.startswith('a')).select(df_reviews_clean.user_name).show(10)\n",
    "df_reviews_clean.filter(df_reviews.stars == 5).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d058877d-bc86-43bb-828c-a2067f8b191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    avg(thumbs_up)|\n",
      "+------------------+\n",
      "|1.0892641073589264|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# wyliczenie średniej wartości z kolumny\n",
    "df_reviews_clean.select(avg(df_reviews_clean.thumbs_up)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f19474fc-3c64-4b80-b85b-25cd0879f0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|         thumbs_up|\n",
      "+-------+------------------+\n",
      "|  count|             18182|\n",
      "|   mean|1.0892641073589264|\n",
      "| stddev| 4.201003572820717|\n",
      "|    min|                 0|\n",
      "|    max|               106|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ale możemy się dowiedzieć tego i więcej w sposób podobny do tego z biblioteki pandas\n",
    "df_reviews_clean.select(df_reviews_clean.thumbs_up).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed730dd2-e1a2-4c0e-9adb-f273464db12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|recipe_code|sum(thumbs_down)|\n",
      "+-----------+----------------+\n",
      "|       2832|             488|\n",
      "|       9739|             354|\n",
      "|      17826|             328|\n",
      "|      18345|             313|\n",
      "|      12003|             306|\n",
      "|       4383|             301|\n",
      "|      41095|             275|\n",
      "|       8202|             272|\n",
      "|       6504|             264|\n",
      "|       6086|             262|\n",
      "+-----------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "df_reviews_clean.groupby('recipe_code').agg({'thumbs_down': 'sum'}).sort(desc('sum(thumbs_down)')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76624c52-6f6b-4244-a3bc-fe7394754207",
   "metadata": {},
   "source": [
    "Dla potrzeb laboratorium została stworzona funkcja, która pozwoli na generowanie datasetu i zapisane go w pliku csv na początek, aby zaprezentować podstawowe typy danych Sparka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fa6c72-6675-498a-a3d0-ff32d8eb89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deklaracja zbiorów wartości dla poszczególnych kolumn przyszłego zbioru danych\n",
    "header = ['id', 'firstname', 'lastname', 'age', 'salary']\n",
    "firstnames = ['Adam', 'Katarzyna', 'Krzysztof', 'Marek', 'Aleksandra', 'Zbigniew', 'Wojciech', 'Mieczysław', 'Agata', 'Wisława']\n",
    "lastnames = ['Mieczykowski', 'Kowalski', 'Malinowski' , 'Szczaw', 'Glut', 'Barański', 'Brzęczyszczykiewicz', 'Wróblewski', 'Wlotka', 'Pysla']\n",
    "age = {'min': 18, 'max': 68}\n",
    "salary = {'min': 3200, 'max': 12500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8223d-1d17-4a54-8724-446c7062e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f9c979-abb6-48a1-8dfa-8a9efcbbd8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja do generowania fikcyjnego datasetu\n",
    "# n_rows oznacza ilość wierszy, którą chcemy finalnie uzyskać\n",
    "\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_dataset(filename, n_rows=100, chunk_size=100000):\n",
    "    rows = []\n",
    "    rows.append(header)\n",
    "    mu = (salary['max'] + salary['min']) / 2\n",
    "    sigma = 1000\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as filehandler:\n",
    "        \n",
    "        for id in tqdm(range(1, n_rows + 1), total=n_rows, desc=\"Building dataset...\"):\n",
    "            row = [\n",
    "                f'{id}', \n",
    "                f'{random.choice(firstnames)}', \n",
    "                f'{random.choice(lastnames)}', \n",
    "                f\"{random.randint(age['min'], age['max'])}\",\n",
    "                f\"{round(float(random.normalvariate(mu=mu, sigma=sigma)), 2)}\"\n",
    "            ]\n",
    "            rows.append(row)\n",
    "            if id % chunk_size == 0:\n",
    "                filehandler.writelines([f\"{','.join(row)}\\n\" for row in rows])\n",
    "                rows = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91806375-7c41-4073-8b95-200f02daca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# około 750MB zostanie zapisanych w pliku csv, dostosuj ilość rekordów do swoich potrzeb\n",
    "# build_dataset('./data/employee.csv', 20_000_000)\n",
    "build_dataset('./data/employee_200m.csv', 200_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e20456-ca25-4873-91ed-799d93bc3c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# więcej magicznych metod w Jupyter Notebooku: https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "# wczytanie pliku csv przez spark\n",
    "# df = spark.read.csv('employee.csv', header=True)\n",
    "df = spark.read.csv('./data/employee.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c2899b-4203-491b-9e23-fd334ff69054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2467420b-a44f-44bc-be5f-d0d92343d20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n",
      "+---+----------+-------------------+---+--------+\n",
      "| id| firstname|           lastname|age|  salary|\n",
      "+---+----------+-------------------+---+--------+\n",
      "|  1|  Zbigniew|           Barański| 46| 8797.82|\n",
      "|  2| Krzysztof|           Kowalski| 33| 7441.71|\n",
      "|  3| Krzysztof|Brzęczyszczykiewicz| 60| 8502.79|\n",
      "|  4|      Adam|         Wróblewski| 36|10258.55|\n",
      "|  5|   Wisława|           Barański| 43|  9006.9|\n",
      "|  6|Aleksandra|         Wróblewski| 38| 8796.75|\n",
      "|  7|     Agata|               Glut| 64| 9252.93|\n",
      "|  8| Krzysztof|             Wlotka| 58| 8470.38|\n",
      "|  9|Mieczysław|              Pysla| 51|10216.48|\n",
      "| 10| Krzysztof|Brzęczyszczykiewicz| 48| 7853.63|\n",
      "+---+----------+-------------------+---+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 235 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wypisujemy schemat i 10 pierwszych wierszy utworzonego obiektu Spark DataFrame\n",
    "df.printSchema()\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "085a27ef-3e27-47c4-babd-a1c8a5051989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# przykład wykorzystania funkcji transform, która mapuje wykonanie stworzonej funkcji tu_upper_str_columns na istniejącą kolumnę\n",
    "# i zwraca nową ramkę z dodatkową kolumną\n",
    "from pyspark.sql.functions import upper\n",
    "\n",
    "def to_upper_str_columns(df, column_name, new_column_name):\n",
    "    return df.withColumn(new_column_name, upper(df[column_name]))\n",
    "\n",
    "df = df.transform(to_upper_str_columns, \"firstname\", \"firstname_upper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "999e4f38-face-4446-a546-6c780dd1efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+---+--------+---------------+\n",
      "| id| firstname|    lastname|age|  salary|firstname_upper|\n",
      "+---+----------+------------+---+--------+---------------+\n",
      "|  1|     Marek|    Barański| 38|  7243.9|          MAREK|\n",
      "|  2|Mieczysław|Mieczykowski| 50| 7725.26|     MIECZYSŁAW|\n",
      "|  3|  Wojciech|  Wróblewski| 63|  9648.6|       WOJCIECH|\n",
      "|  4|   Wisława|    Kowalski| 57| 6856.65|        WISŁAWA|\n",
      "|  5| Katarzyna|  Malinowski| 38| 8205.95|      KATARZYNA|\n",
      "|  6|     Agata|  Malinowski| 20|10381.84|          AGATA|\n",
      "|  7|     Agata|Mieczykowski| 43| 8076.51|          AGATA|\n",
      "|  8|      Adam|    Barański| 52| 7888.46|           ADAM|\n",
      "|  9|Mieczysław|Mieczykowski| 41| 8723.81|     MIECZYSŁAW|\n",
      "| 10| Krzysztof|  Malinowski| 24| 8840.09|      KRZYSZTOF|\n",
      "+---+----------+------------+---+--------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d71630-d5eb-4582-b5cf-e3b6e592262f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3153026"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtrowanie numeryczne, ale tu na kolumnie typu str - czy jest poprawne?\n",
    "df.filter(df[\"salary\"] > 10000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44f43015-b102-4456-9f79-7c584196859d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# na ile partycji została nasza ramka danych rozrzucona po \"klastrze\"?\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b29a9b96-b9b0-4177-8964-941eaa261eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3153026"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# mierzymy czas operacji przy domyślnej liczbie partycji\n",
    "df.filter(df[\"salary\"] > 10000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09b8b448-2543-4b41-a6e9-632dab529677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5677ad82-4cdc-4aee-a364-53da0d99d222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e9170d-fd62-4c26-a2ae-74e3a0dfab3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3153026"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# mierzymy czas operacji przy domyślnej liczbie partycji\n",
    "df.filter(df[\"salary\"] > 10000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dec3fec4-39c6-45bb-8c50-02a9661ca70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      avg(salary)|\n",
      "+-----------------+\n",
      "|7850.165355485972|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "\n",
    "df.select(mean(df.salary)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbadd267-60ff-4e0e-94db-f189e54d7d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+\n",
      "|firstname_age|    18|    19|    20|    21|    22|    23|    24|    25|    26|    27|    28|    29|    30|    31|    32|    33|    34|    35|    36|    37|    38|    39|    40|    41|    42|    43|    44|    45|    46|    47|    48|    49|    50|    51|    52|    53|    54|    55|    56|    57|    58|    59|    60|    61|    62|    63|    64|    65|    66|    67|    68|\n",
      "+-------------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+\n",
      "|         Adam|392910|391511|391831|392514|392123|390959|392120|391800|391743|391707|392745|391514|392037|391865|392924|392846|391072|392022|391979|392011|392492|392584|391716|392710|390952|391864|392474|392202|391755|391901|391539|391729|391328|392564|392733|392335|391790|392254|391679|391456|391825|392791|393106|390364|391836|392955|392315|392121|392561|392013|392901|\n",
      "|        Agata|392453|391865|392733|393227|392026|391425|392070|393101|392228|393218|391339|391464|392699|392379|393046|392980|392476|391552|391754|392094|392504|392970|390997|391671|391441|391660|392446|392420|391598|393844|392284|391978|391464|393319|392968|391339|391624|391847|391063|392098|391776|392885|392635|391798|393110|392226|391827|393522|392358|393082|391845|\n",
      "|   Aleksandra|392152|391928|392792|392018|391863|392229|392963|392192|391759|392971|392213|391482|392833|391729|392700|392736|391241|392687|392291|391051|391803|391207|390727|391150|391876|392225|392663|393111|392952|392573|391865|391710|391695|393417|392850|393636|391714|391910|393158|392329|392237|392310|393141|392659|393115|391752|393217|392392|391658|391149|392641|\n",
      "|    Katarzyna|390759|392436|391811|391825|392120|391656|392250|390798|392105|392196|392171|392691|390508|391242|391477|391419|392203|392008|392380|392522|392322|392835|392051|393064|391182|392195|391981|391662|392984|391164|392850|392347|392363|392349|392886|391424|392313|391728|391505|392430|391446|391288|391060|391213|392036|391984|393011|391779|392517|392146|391598|\n",
      "|    Krzysztof|392007|391430|392383|391241|393824|390388|392688|391925|392875|392102|391381|392540|392747|392345|392529|391690|391785|392145|391950|393051|392643|391998|391836|393049|392691|391356|391675|392525|392919|391294|391554|392866|391722|391733|392138|390907|392127|391626|391542|391759|391874|392220|392896|391437|392032|393147|391451|392298|393274|391650|392627|\n",
      "|        Marek|391613|390726|391666|391669|391157|392540|392962|392196|392169|391459|392414|392347|391428|392022|392154|392911|391838|393345|392687|392578|392298|391091|393163|391539|392539|393921|392281|391960|392102|392801|392460|392573|392265|392038|393331|391627|391986|391884|392688|391922|392705|392112|393118|392253|393040|392316|391573|392731|393279|392274|391928|\n",
      "|   Mieczysław|392957|391610|392628|392004|392218|392910|391153|392810|392819|391225|391517|392814|391689|392460|392404|391917|392077|391560|392745|393409|393474|391483|392807|391366|392328|391618|392524|393026|393900|391654|391092|392024|392176|392201|391814|392896|392187|392503|391305|393227|392345|391948|392982|391820|392299|392111|391754|392710|392961|392207|392810|\n",
      "|      Wisława|391237|393727|391764|392157|392784|392362|391989|391987|391375|391938|392524|391317|392938|391990|392557|392416|391783|391394|392886|392205|391312|392496|393898|392776|392716|391897|391836|392263|391287|392627|391892|392235|391788|392718|391990|391740|391438|392018|392921|392702|391958|391184|391211|391969|391480|393611|392973|392098|391805|390829|392972|\n",
      "|     Wojciech|391361|391415|392111|391839|390758|391153|392823|391883|392151|392251|392774|392044|391374|391018|391324|392101|391397|392877|393132|391786|392395|391280|392610|392229|392266|392700|391339|390890|391914|392065|393268|391573|391363|392108|392375|392006|393719|391913|392006|392377|392751|393199|392905|392261|391316|392010|392296|391133|392119|392095|391881|\n",
      "|     Zbigniew|392162|391303|392945|392280|392069|392528|391201|392526|392478|392405|392672|392807|392436|392489|392141|392765|392382|392538|392872|391167|392225|392946|391746|392064|392358|391958|391785|391719|391684|391926|391333|392039|392077|392291|392068|391523|391800|393239|393280|392724|390995|391611|392488|391968|391428|391168|391912|392632|392875|392715|392536|\n",
      "+-------------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# macierz częstości dla dwóch kolumn - uwaga dla bardzo różnorodnych danych!\n",
    "df.crosstab(\"firstname\", \"age\").sort(\"firstname_age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f9d91cca-51b1-4e43-9ed5-d934719e1363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (5)\n",
      "+- Exchange (4)\n",
      "   +- Project (3)\n",
      "      +- Filter (2)\n",
      "         +- Scan csv  (1)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [5]: [id#1219, firstname#1220, lastname#1221, age#1222, salary#1223]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/C:/Users/Krzysztof/__projects/__pyspark_local_aiids/data/employee.csv]\n",
      "PushedFilters: [IsNotNull(firstname), StringContains(firstname,ski)]\n",
      "ReadSchema: struct<id:int,firstname:string,lastname:string,age:int,salary:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [5]: [id#1219, firstname#1220, lastname#1221, age#1222, salary#1223]\n",
      "Condition : (isnotnull(firstname#1220) AND Contains(firstname#1220, ski))\n",
      "\n",
      "(3) Project\n",
      "Output [6]: [id#1219, firstname#1220, lastname#1221, age#1222, salary#1223, upper(firstname#1220) AS firstname_upper#1256]\n",
      "Input [5]: [id#1219, firstname#1220, lastname#1221, age#1222, salary#1223]\n",
      "\n",
      "(4) Exchange\n",
      "Input [6]: [id#1219, firstname#1220, lastname#1221, age#1222, salary#1223, firstname_upper#1256]\n",
      "Arguments: RoundRobinPartitioning(12), REPARTITION_BY_NUM, [plan_id=1095]\n",
      "\n",
      "(5) AdaptiveSparkPlan\n",
      "Output [6]: [id#1219, firstname#1220, lastname#1221, age#1222, salary#1223, firstname_upper#1256]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# funkcja explain może przydać się w przypadku bardziej zaawansowanego debuggingu, optymalizacji i zrozumienia\n",
    "# kolejności działania niektórych elementów silnika Spark\n",
    "query = df.filter(df.firstname.contains('ski'))\n",
    "query.explain(mode='formatted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4baa4a58-2b6c-4bdd-a95f-92ee38c569cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\hadoop\n"
     ]
    }
   ],
   "source": [
    "# jeżeli przy zapisie w systemie Windows pojawia się błąd, to jest to związane z\n",
    "# brakiem lub niewłaściwym sposobem konfiguracji winutils:\n",
    "# https://github.com/steveloughran/winutils\n",
    "\n",
    "# krok 1 - pobieramy całą zawartość folderu dla naszej wersji Hadoop - tu mamy wersję 3.0.0 \n",
    "# (możemy sklonować całe repozytorium poleceniem git clone https://github.com/steveloughran/winutils lub\n",
    "# pobrać je jako plik zip bezpośrednio ze strony GitHub)\n",
    "# krok 2 - tworzymy folder, i mapujemy go na zmienną środowiskową HADOOP_HOME\n",
    "# krok 3 - kopiujemy folder bin z pobranego folderu HADOOP-3.0.0 (cały folder) do folderu z pkt. 2\n",
    "# krok 4 - dodajemy ścieżkę folder z kroku 2/bin do zmiennej środowiskowej path\n",
    "\n",
    "# krok 5 - przeładowujemy zmienne środowiskowe co zonacza konieczność zamknięcia np. VSC oraz przeładowania\n",
    "# jądra Python i uruchomienia sesji Spark od nowa\n",
    "\n",
    "# sprawdzamy jaka jest wartość zmiennej środowiskowej HADOOP_HOME\n",
    "!echo %hadoop_home%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd774b-c82c-4f47-8d4f-ecdc20f7b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapisujemy ramkę do plików parquet\n",
    "# zwróć uwagę na liczbę utworzonych plików\n",
    "\n",
    "df.write.parquet('./data/parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d26cbd4-f24a-4f08-b99c-cfce31f7b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lub chcąc nadpisać już istniejące dane - w trybie overwrite\n",
    "df.write.mode(\"overwrite\").parquet('./data/parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c686a98-e41d-4d67-8a33-840315a0903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c9de6-9853-447b-8cbb-73bd9c42a50c",
   "metadata": {},
   "source": [
    "### Zadania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f488442-a201-4e96-8b2b-ad4b49a15f36",
   "metadata": {},
   "source": [
    "**Zadanie 1**  \n",
    "Na zbiorze danych '_Recipe Reviews ..._' wykonaj:  \n",
    "1.1  Zmień nazwę pierwszej kolumny z `_c0` na `id`.  \n",
    "1.2  Wyświetl 10 najwyższych wartości w kolumnie `reply_count`.  \n",
    "1.3  Wyświetl 10 najwyższych sum wartości w kolumnie `best_score` dla każdego przepisu (grupowanie).  \n",
    "1.4  Które 10 przepisów miało najwięcej komentarzy?  \n",
    "1.5  Wyświetl rozkład wartości w kolumnie `stars`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20e89b-1ef9-48ae-ab6a-5ecf0876c042",
   "metadata": {},
   "source": [
    "**Zadanie 2**  \n",
    "Wczytaj zbiór danych `employee` nakazując Sparkowi wywnioskowanie bardziej optymalnych typów danych niż domyślny typ `string`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f683ee90-6493-4244-b004-cae1d1fb9121",
   "metadata": {},
   "source": [
    "**Zadanie 3**  \n",
    "Jaki jest czas wykonania operacji `df.filter(df[\"salary\"] > 10000).count()` tym razem przy numerycznym typie kolumny `salary`? Jest jakaś różnica?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63881899-1e19-4376-94cf-e0701d11b7f4",
   "metadata": {},
   "source": [
    "**Zadanie 4**  \n",
    "Wykorzystując przykład z dokumentacji klasy `Bucketizer` (https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.Bucketizer.html) podziel dane w kolumnie `age` zbioru `employee` na buckety co 10 lat (10-19, 20-29, ..., 60-69) i wyświetl te dane dla 20 pierwszych wierszy w formie surowej oraz całość grupując po bucketach i licząc ile osób znalazło się w każdym z nich."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2818054-ca1b-4a91-8463-7ed65ac05984",
   "metadata": {},
   "source": [
    "## Rozwiązania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b49768f-91f0-4423-a8da-121c8b83c3ef",
   "metadata": {},
   "source": [
    "**Zadanie 1.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f880dea3-0bd1-4a0f-a53e-6a2ca9911988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'recipe_number',\n",
       " 'recipe_code',\n",
       " 'recipe_name',\n",
       " 'comment_id',\n",
       " 'user_id',\n",
       " 'user_name',\n",
       " 'user_reputation',\n",
       " 'created_at',\n",
       " 'reply_count',\n",
       " 'thumbs_up',\n",
       " 'thumbs_down',\n",
       " 'stars',\n",
       " 'best_score',\n",
       " 'text']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gdyby to był pandas\n",
    "col = list(df_reviews_clean.columns)\n",
    "df.columns = ['id'] + col[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "514dd305-40ff-4c72-bcdc-c8deeaa06f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'recipe_number',\n",
       " 'recipe_code',\n",
       " 'recipe_name',\n",
       " 'comment_id',\n",
       " 'user_id',\n",
       " 'user_name',\n",
       " 'user_reputation',\n",
       " 'created_at',\n",
       " 'reply_count',\n",
       " 'thumbs_up',\n",
       " 'thumbs_down',\n",
       " 'stars',\n",
       " 'best_score',\n",
       " 'text']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "139f99f1-e949-4f92-867b-ccb2f1caed32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------+------------------+--------------------+--------------+----------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "| id|recipe_number|recipe_code|       recipe_name|          comment_id|       user_id|       user_name|user_reputation|created_at|reply_count|thumbs_up|thumbs_down|stars|best_score|                text|\n",
      "+---+-------------+-----------+------------------+--------------------+--------------+----------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "|  0|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_9iFLIhMa8QaG|         Jeri326|              1|1665619889|          0|        0|          0|    5|       527|I tweaked it a li...|\n",
      "|  1|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_Lu6p25tmE77j|         Mark467|             50|1665277687|          0|        7|          0|    5|       724|Bush used to have...|\n",
      "|  2|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_s0LwgpZ8Jsqq|      Barbara566|             10|1664404557|          0|        3|          0|    5|       710|I have a very com...|\n",
      "|  3|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_fqrybAdYjgjG|      jeansch123|              1|1661787808|          2|        2|          0|    0|       581|In your introduct...|\n",
      "|  4|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_XXWKwVhKZD69|        camper77|             10|1664913823|          1|        7|          0|    0|       820|Wonderful! I made...|\n",
      "|  5|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_BALTQJIvWtYr|         nikhita|              1|1661354351|          0|        3|          1|    5|       518|amazing! my boyfr...|\n",
      "|  6|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_HuJVXMzQqJoI|       Sandy1256|              1|1644088805|          0|       11|          0|    5|       833|Wow!!!  This reci...|\n",
      "|  7|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_uj79hCc4xVhm|         Towanka|              1|1643942114|          0|       28|          2|    0|       891|This is delicious...|\n",
      "|  8|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_xDTU4BqIVIc9|           Quest|              1|1643933124|          0|        6|          0|    5|       693|I absolutely love...|\n",
      "|  9|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_cDoX9ujcQEoc|     Susannah953|              1|1643237839|          0|        0|          0|    5|       404|I make this a lot...|\n",
      "| 10|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_a1kMC63ejmcn|jillanglemyer810|              1|1643127683|          0|        3|          0|    5|       706|Best and easiest ...|\n",
      "| 11|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_rLDRFmNx35zU|       Leslie126|              1|1642892566|          0|        2|          1|    5|       617|Best white chili ...|\n",
      "| 12|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_lPW6uyGJNSN0|       Cindy4876|              1|1642353692|          0|        1|          0|    5|       633|This recipe was e...|\n",
      "| 13|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_EXBl66u7yYkp|         Xzercie|              1|1645506015|          0|        4|          2|    5|       672|I made this along...|\n",
      "| 14|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_tOkZoHuF5wQW|       TERESA062|              1|1641956093|          0|        5|          1|    5|       585|Fantastic, but mi...|\n",
      "| 15|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_pTdidnO4Qvj9|      Mary-Lynne|              1|1641825491|          0|        1|          0|    5|       608|This is a fabulou...|\n",
      "| 16|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_zSpLgUzFZKjk|           Petri|              1|1641578704|          0|        0|          0|    4|       449|Delicious, If you...|\n",
      "| 17|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_DAo1aayKpI6d|      Marilyn034|              1|1638206887|          0|        3|          0|    5|       637|made according to...|\n",
      "| 18|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_YTq5zXIY38wL|    Jeannette653|              1|1637520980|          0|        3|          0|    5|       602|My new favorite s...|\n",
      "| 19|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_xwWa3ShkvfPQ|        Scott967|              1|1637441853|          1|       11|          1|    5|       820|This is a hit in ...|\n",
      "+---+-------------+-----------+------------------+--------------------+--------------+----------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews_clean.withColumnRenamed('_c0', 'id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf6ae7e5-bb86-4923-8a40-67b120a94ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, recipe_number: string, recipe_code: string, recipe_name: string, comment_id: string, user_id: string, user_name: string, user_reputation: string, created_at: int, reply_count: int, thumbs_up: int, thumbs_down: int, stars: int, best_score: int, text: string]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f691ee1b-20b7-44b8-a980-b2f815d7b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# musimy nadpisać zmienną \n",
    "df_reviews_clean = df_reviews_clean.withColumnRenamed('_c0', 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b7681c2-b77c-4a55-b60d-45da11dddfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------+------------------+--------------------+--------------+----------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "| id|recipe_number|recipe_code|       recipe_name|          comment_id|       user_id|       user_name|user_reputation|created_at|reply_count|thumbs_up|thumbs_down|stars|best_score|                text|\n",
      "+---+-------------+-----------+------------------+--------------------+--------------+----------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "|  0|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_9iFLIhMa8QaG|         Jeri326|              1|1665619889|          0|        0|          0|    5|       527|I tweaked it a li...|\n",
      "|  1|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_Lu6p25tmE77j|         Mark467|             50|1665277687|          0|        7|          0|    5|       724|Bush used to have...|\n",
      "|  2|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_s0LwgpZ8Jsqq|      Barbara566|             10|1664404557|          0|        3|          0|    5|       710|I have a very com...|\n",
      "|  3|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_fqrybAdYjgjG|      jeansch123|              1|1661787808|          2|        2|          0|    0|       581|In your introduct...|\n",
      "|  4|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_XXWKwVhKZD69|        camper77|             10|1664913823|          1|        7|          0|    0|       820|Wonderful! I made...|\n",
      "|  5|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_BALTQJIvWtYr|         nikhita|              1|1661354351|          0|        3|          1|    5|       518|amazing! my boyfr...|\n",
      "|  6|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_HuJVXMzQqJoI|       Sandy1256|              1|1644088805|          0|       11|          0|    5|       833|Wow!!!  This reci...|\n",
      "|  7|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_uj79hCc4xVhm|         Towanka|              1|1643942114|          0|       28|          2|    0|       891|This is delicious...|\n",
      "|  8|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_xDTU4BqIVIc9|           Quest|              1|1643933124|          0|        6|          0|    5|       693|I absolutely love...|\n",
      "|  9|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_cDoX9ujcQEoc|     Susannah953|              1|1643237839|          0|        0|          0|    5|       404|I make this a lot...|\n",
      "| 10|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_a1kMC63ejmcn|jillanglemyer810|              1|1643127683|          0|        3|          0|    5|       706|Best and easiest ...|\n",
      "| 11|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_rLDRFmNx35zU|       Leslie126|              1|1642892566|          0|        2|          1|    5|       617|Best white chili ...|\n",
      "| 12|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_lPW6uyGJNSN0|       Cindy4876|              1|1642353692|          0|        1|          0|    5|       633|This recipe was e...|\n",
      "| 13|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_EXBl66u7yYkp|         Xzercie|              1|1645506015|          0|        4|          2|    5|       672|I made this along...|\n",
      "| 14|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_tOkZoHuF5wQW|       TERESA062|              1|1641956093|          0|        5|          1|    5|       585|Fantastic, but mi...|\n",
      "| 15|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_pTdidnO4Qvj9|      Mary-Lynne|              1|1641825491|          0|        1|          0|    5|       608|This is a fabulou...|\n",
      "| 16|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_zSpLgUzFZKjk|           Petri|              1|1641578704|          0|        0|          0|    4|       449|Delicious, If you...|\n",
      "| 17|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_DAo1aayKpI6d|      Marilyn034|              1|1638206887|          0|        3|          0|    5|       637|made according to...|\n",
      "| 18|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_YTq5zXIY38wL|    Jeannette653|              1|1637520980|          0|        3|          0|    5|       602|My new favorite s...|\n",
      "| 19|          001|      14299|Creamy White Chili|sp_aUSaElGf_14299...|u_xwWa3ShkvfPQ|        Scott967|              1|1637441853|          1|       11|          1|    5|       820|This is a hit in ...|\n",
      "+---+-------------+-----------+------------------+--------------------+--------------+----------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews_clean.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f95cc-5eb8-4aed-a51a-584dc52eb1c0",
   "metadata": {},
   "source": [
    "**Zadanie 1.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bece3a7a-c5f3-46d2-a2b8-8ce6f3f94723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-----------+--------------------+--------------------+--------------------+--------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "| id|recipe_number|recipe_code|         recipe_name|          comment_id|             user_id|     user_name|user_reputation|created_at|reply_count|thumbs_up|thumbs_down|stars|best_score|                text|\n",
      "+---+-------------+-----------+--------------------+--------------------+--------------------+--------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "| 17|          002|       3309|Best Ever Banana ...|sp_aUSaElGf_3309_...|u_1tOHujEFJQIEVu0...|  OrangeBowtie|              0|1622648873|          3|        5|          0|    5|       354|The title is not ...|\n",
      "|  8|          003|       2832|   Cheeseburger Soup|sp_aUSaElGf_2832_...|      u_inTFTX8AEJ0X|ladypenny36619|              1|1659170678|          3|        1|         20|    5|       495|I love this recip...|\n",
      "| 40|          003|       2832|   Cheeseburger Soup|sp_aUSaElGf_2832_...|u_1oKd0xoTyJRTE0q...|             K|              1|1622648880|          3|        6|         41|    0|       127|Just once I&#39;d...|\n",
      "| 43|          003|       2832|   Cheeseburger Soup|sp_aUSaElGf_2832_...|u_1oKd0qIiH6zumOD...|          Elle|              1|1622648880|          3|        4|         61|    2|       110|I made this recip...|\n",
      "|  5|          013|      32480|Basic Homemade Bread|sp_aUSaElGf_32480...|      u_mliuhxCdSTIo|      James626|              1|1655857389|          3|       15|         31|    0|       549|I waited three ho...|\n",
      "|  0|          040|       8431|Rhubarb Custard Bars|sp_aUSaElGf_8431_...|      u_VgdSEmx4XglO|    Frances442|              1|1656521871|          3|        0|          0|    0|       505|Hello, we usually...|\n",
      "|  1|          063|      24886|Chicken and Dumpl...|sp_aUSaElGf_24886...|      u_k6carS36aBxW|        Fay117|              1|1644615715|          2|       30|         32|    0|       674|southern dumpling...|\n",
      "| 22|          001|      14299|  Creamy White Chili|sp_aUSaElGf_14299...|      u_wYANTnDQZ8Ud|      Sandy326|              1|1633371450|          2|        5|          5|    5|       650|Very good!! Easy ...|\n",
      "|  8|          089|       1324| Porcupine Meatballs|sp_aUSaElGf_1324_...|      u_guvaH2rKhSgt|       pammy54|             60|1648844298|          2|       33|          8|    5|       825|As per other comm...|\n",
      "| 25|          006|      21444|Favorite Chicken ...|sp_aUSaElGf_21444...|u_1tOHukW0cVBCqkC...|       BlueBee|              0|1622648873|          2|       10|         31|    0|       162|A cup of butter a...|\n",
      "+---+-------------+-----------+--------------------+--------------------+--------------------+--------------+---------------+----------+-----------+---------+-----------+-----+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews_clean.sort(df_reviews_clean.reply_count, ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5daff-c425-4394-91b5-1a2785636fdc",
   "metadata": {},
   "source": [
    "**Zadanie 1.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5fbcdac-27fc-4e1d-bf82-a4071cb2336c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|recipe_number|sum(best_score)|\n",
      "+-------------+---------------+\n",
      "|          003|          98863|\n",
      "|          001|          85497|\n",
      "|          004|          64880|\n",
      "|          002|          64247|\n",
      "|          006|          60755|\n",
      "|          013|          59867|\n",
      "|          007|          59195|\n",
      "|          010|          54032|\n",
      "|          009|          51975|\n",
      "|          012|          47905|\n",
      "+-------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# df_reviews_clean.groupby('id').agg({'best_score': 'sum'}).sort(desc('sum(best_score)')).show(10)\n",
    "\n",
    "# lub\n",
    "df_reviews_clean.groupby('recipe_number').agg({'best_score': 'sum'}).sort('sum(best_score)', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ade977-61e7-44a9-a9fa-678321fa0687",
   "metadata": {},
   "source": [
    "**Zadanie 1.4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c4eb2a0-524a-4cd1-9b10-0ba5d2ba61f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----+\n",
      "|recipe_number|         recipe_name|count|\n",
      "+-------------+--------------------+-----+\n",
      "|          003|   Cheeseburger Soup|  725|\n",
      "|          001|  Creamy White Chili|  654|\n",
      "|          002|Best Ever Banana ...|  509|\n",
      "|          009|Enchilada Casser-...|  421|\n",
      "|          013|Basic Homemade Bread|  397|\n",
      "|          006|Favorite Chicken ...|  395|\n",
      "|          007|Flavorful Chicken...|  368|\n",
      "|          004|Amish Breakfast C...|  338|\n",
      "|          010|Zucchini Pizza Ca...|  332|\n",
      "|          012|    Cauliflower Soup|  324|\n",
      "+-------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews_clean.groupby('recipe_number', 'recipe_name').count().sort('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fb16521-beac-47b1-8505-8b9eded6fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|         recipe_name|sum(reply_count)|\n",
      "+--------------------+----------------+\n",
      "|   Cheeseburger Soup|              16|\n",
      "|Lemon Blueberry B...|              13|\n",
      "|Basic Homemade Bread|              12|\n",
      "|Simple Au Gratin ...|              10|\n",
      "|  Creamy White Chili|              10|\n",
      "|    Simple Taco Soup|               9|\n",
      "| Traditional Lasagna|               8|\n",
      "|Contest-Winning N...|               8|\n",
      "| Porcupine Meatballs|               8|\n",
      "|Favorite Chicken ...|               6|\n",
      "+--------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews_clean.groupBy(\"recipe_name\").agg({'reply_count': 'sum'}).sort(\"sum(reply_count)\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f28994-38a0-4a9d-aaa8-b11086910bee",
   "metadata": {},
   "source": [
    "**Zadanie 1.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81e86416-510e-4ef1-af64-1af20a400493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|stars|count|\n",
      "+-----+-----+\n",
      "|    1|  280|\n",
      "|    3|  490|\n",
      "|    5|13829|\n",
      "|    4| 1655|\n",
      "|    2|  232|\n",
      "|    0| 1696|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews_clean.groupby('stars').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f723db-a7f7-4c39-89bf-87dfdc7c69cf",
   "metadata": {},
   "source": [
    "**Zadanie 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b42dca5-14b0-48e4-b45e-3fc66538531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bez infer schema\n",
    "df_employee = spark.read.csv('./data/employee.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d79aa5b-83f8-4944-91b3-f6490464bbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2166e60a-a522-49ed-ab26-c5ce3f35f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 12.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "314073"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_employee.filter(df_employee[\"salary\"] > 10000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "85d5c390-1fa4-4abf-a450-248ac77b482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(salary#1665) AND (cast(salary#1665 as int) > 10000))\n",
      "+- FileScan csv [id#1661,firstname#1662,lastname#1663,age#1664,salary#1665] Batched: false, DataFilters: [isnotnull(salary#1665), (cast(salary#1665 as int) > 10000)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/Krzysztof/__projects/__pyspark_local_aiids/data/employe..., PartitionFilters: [], PushedFilters: [IsNotNull(salary)], ReadSchema: struct<id:string,firstname:string,lastname:string,age:string,salary:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee.filter(df_employee[\"salary\"] > 10000).explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176cf32-e4ca-4328-98c2-692ffb056f89",
   "metadata": {},
   "source": [
    "**Zadanie 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dca80b9-1f90-4be8-9d75-16d012f77cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z infer schema\n",
    "df_employee = spark.read.csv('./data/employee.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2abdace-06eb-4f48-abbc-7c8606759a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd94c345-033d-4149-aecb-200fb3c51520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 10.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "314855"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_employee.filter(df_employee[\"salary\"] > 10000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0ebd0eef-d008-4f8b-9b71-153808a35ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(salary#1626) AND (salary#1626 > 10000.0))\n",
      "+- FileScan csv [id#1622,firstname#1623,lastname#1624,age#1625,salary#1626] Batched: false, DataFilters: [isnotnull(salary#1626), (salary#1626 > 10000.0)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/Krzysztof/__projects/__pyspark_local_aiids/data/employe..., PartitionFilters: [], PushedFilters: [IsNotNull(salary), GreaterThan(salary,10000.0)], ReadSchema: struct<id:int,firstname:string,lastname:string,age:int,salary:double>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employee.filter(df_employee[\"salary\"] > 10000).explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45016d-b3c5-455a-a391-10398b00ded2",
   "metadata": {},
   "source": [
    "**Zadanie 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1f0f9b1-5958-4656-a022-765cbedf28fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 19, 29, 39, 49, 59, 69]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(9, 70, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c4c67ef8-15e7-4ace-b9c7-ebb80e952551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.2.5-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.2.5-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.1/12.9 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.2/12.9 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.0/12.9 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.3/12.9 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 8.7 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pojawił się błąd o braku biblioteki numpy - instalujemy\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d173b1d-ad00-4f39-8308-881e1dca1e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 19, 29, 39, 49, 59, 69]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(9, 70, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "daed378a-9ae3-440f-ba70-486640974476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|buckets|\n",
      "+---+-------+\n",
      "|46 |3.0    |\n",
      "|33 |2.0    |\n",
      "|60 |5.0    |\n",
      "|36 |2.0    |\n",
      "|43 |3.0    |\n",
      "|38 |2.0    |\n",
      "|64 |5.0    |\n",
      "|58 |4.0    |\n",
      "|51 |4.0    |\n",
      "|48 |3.0    |\n",
      "|35 |2.0    |\n",
      "|64 |5.0    |\n",
      "|42 |3.0    |\n",
      "|23 |1.0    |\n",
      "|29 |2.0    |\n",
      "|48 |3.0    |\n",
      "|26 |1.0    |\n",
      "|55 |4.0    |\n",
      "|66 |5.0    |\n",
      "|56 |4.0    |\n",
      "+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "bucketizer = Bucketizer()\n",
    "bucketizer.setSplits(range(9, 70, 10))\n",
    "bucketizer.setInputCol(\"age\")\n",
    "bucketizer.setOutputCol(\"buckets\")\n",
    "# bucketed = bucketizer.setHandleInvalid(\"keep\").transform(df_employee).collect()\n",
    "bucketed = bucketizer.setHandleInvalid(\"keep\").transform(df_employee.select(\"age\"))\n",
    "bucketed.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
